//
//  main.cpp
//  LoopClosure
//
//  Created by Lili on 2016-02-16.
//  Copyright Â© 2016 jimmy. All rights reserved.
//

#include <iostream>
#include "cvxImage_310.hpp"
#include <string>
#include "cvxIO.hpp"
#include <unordered_map>
#include "ms7ScenesUtil.hpp"
#include "bt_rnd_regressor_builder.h"
#include "bt_rnd_regressor.h"

using std::string;

#if 1

static void help()
{
    printf("program     modelFile  RGBImageList depthImageList cameraPoseList numSamplePerImage maxCheck dataset_param saveFilePrefix\n");
    printf("BT_RND_test bt_RF.txt  rgbs.txt     depth.txt      poses.txt      5000              32       4scenes_param.txt  to3d \n");
    printf("parameter fits to MS 7 Scenes, TUM dataset, 4 Scenes\n");
    printf("multiple 3D prediction ordered by feature distances, save files to result folder\n");
}

int main(int argc, const char * argv[])
{
    if (argc != 8) {
        printf("argc is %d, should be 8\n", argc);
        help();
        return -1;
    }
    
    const char * model_file = argv[1];
    const char * rgb_image_file = argv[2];
    const char * depth_image_file = argv[3];
    const char * camera_to_wld_pose_file = argv[4];
    const int num_random_sample = (int)strtod(argv[5], NULL);
    const int max_check = (int)strtod(argv[6], NULL);

    const char * dataset_param_filename = argv[7];
    const char *prediction_folder        = argv[8];
    const double inlierFeatDist = 0.3;
    const double inlierThreshold = 0.1;
    const double angleThreshold    = 5;
    const double distanceThreshold = 0.05;


    const char * prefix = "to3d_";
    
    assert(num_random_sample > 100);

    vector<string> rgb_files   = Ms7ScenesUtil::read_file_names(rgb_image_file);
    vector<string> depth_files = Ms7ScenesUtil::read_file_names(depth_image_file);
    vector<string> pose_files  = Ms7ScenesUtil::read_file_names(camera_to_wld_pose_file);
    
    assert(rgb_files.size() == depth_files.size());
    assert(rgb_files.size() == pose_files.size());

        DatasetParameter dataset_param;
    dataset_param.readFromFileDataParameter(dataset_param_filename);
 
    vector<string> files = CvxIO::read_files(prediction_folder);
    assert(files.size() > 0);
    
    
    cv::Mat calibration_matrix = dataset_param.camera_matrix();
    const double depth_factor = dataset_param.depth_factor_;
    const double min_depth = dataset_param.min_depth_;
    const double max_depth = dataset_param.max_depth_;
    
    vector<double> angle_errors;
    vector<double> translation_errors;
    
    // save to files
    vector<cv::Mat> estimated_poses;
    vector<string> rgb_img_files;
    vector<string> depth_img_files;
    vector<string> camera_pose_files;

    
    // read model
    BTRNDRegressor model;
    bool is_read = model.load(model_file);
    if (!is_read) {
        printf("Error: can not read from file %s\n", model_file);
        return -1;
    }
    
    const BTRNDTreeParameter & tree_param = model.getTreeParameter();
    const DatasetParameter  & dataset_param = model.getDatasetParameter();
    const bool use_depth = tree_param.is_use_depth_;
    if (use_depth) {
        printf("use depth in the feature.\n");
    }
    else {
        printf("not use depth in the feature.\n");
    }
    
    dataset_param.printSelf();
    tree_param.printSelf();
    
    cv::Mat camera_matrix = dataset_param.camera_matrix();
    const int wh_kernel_size = tree_param.wh_kernel_size_;
    const bool is_use_depth = tree_param.is_use_depth_;
    
    using FeatureType = SCRFRandomFeature;
    // read images, and predict one by one
    for (int k = 0; k<rgb_files.size(); k++) {
        const char *cur_rgb_img_file     = rgb_files[k].c_str();
        const char *cur_depth_img_file   = depth_files[k].c_str();
        const char *cur_pose_file        = pose_files[k].c_str();
        
        cv::Mat rgb_img;
        CvxIO::imread_rgb_8u(cur_rgb_img_file, rgb_img);
        vector<FeatureType>     features;
        vector<Eigen::VectorXf> labels;
        BTRNDUtil::randomSampleFromRgbdImages(cur_rgb_img_file, cur_depth_img_file, cur_pose_file,
                                              num_random_sample, k, dataset_param,
                                              is_use_depth, false,
                                              features, labels);
        BTRNDUtil::extractWHFeatureFromRgbImages(cur_rgb_img_file, features, wh_kernel_size, false);
        assert(features.size() == labels.size());
        
        // predict from the model
        vector<vector<Eigen::VectorXf> > all_predictions;
        vector<vector<float> > all_distances;
        vector<Eigen::VectorXf> all_labels;    // labels
        vector<Eigen::Vector2f> all_locations; // 2d location
        
        for (int j = 0; j<features.size(); j++) {
            vector<Eigen::VectorXf> preds;
            vector<float> dists;
            bool is_predict = model.predict(features[j], rgb_img, max_check, preds, dists);
            if (is_predict) {
                all_predictions.push_back(preds);
                all_distances.push_back(dists);
                all_labels.push_back(labels[j]);
                all_locations.push_back(features[j].p2d_);
            }
        }
        // check prediction quality, only use the smallest one
        const double threshold = 0.1;
        int inlier_num = 0;
        for (int i = 0; i<all_predictions.size(); i++) {
            float dis = (all_labels[i] - all_predictions[i][0]).norm();
            if (dis < threshold) {
                inlier_num++;
            }
        }
        printf("optimal: inlier percentage %f, threshold %f distance\n", 1.0 * inlier_num/all_predictions.size(), threshold);
        
        {
            char save_file[1024] = {NULL};
            sprintf(save_file, "%s_%06d.txt", prefix, k);
            FILE *pf = fopen(save_file, "w");
            assert(pf);
            fprintf(pf, "%s\n", cur_rgb_img_file);
            fprintf(pf, "%s\n", cur_depth_img_file);
            fprintf(pf, "%s\n", cur_pose_file);
            fprintf(pf, "imageLocation\t  groundTruth3d \t num_pred \t, pred_3d, feature_distance \n");
            for (int i = 0; i<all_predictions.size(); i++) {
                Eigen::Vector2f p2d = all_locations[i];
                Eigen::VectorXf p3d = all_labels[i];
                assert(p3d.size() == 3);
                const int num = (int)all_predictions[i].size();
                fprintf(pf, "%d %d\t %lf %lf %lf\n", (int)p2d[0], (int)p2d[1], p3d[0], p3d[1], p3d[2]);
                fprintf(pf, "%d \n", num);
                for (int j = 0; j<all_predictions[i].size(); j++) {
                    Eigen::VectorXf pred   = all_predictions[i][j];
                    assert(pred.size() == 3);
                    float   dist = all_distances[i][j];
                    fprintf(pf, "\t %lf %lf %lf\t %lf\n", pred[0], pred[1], pred[2], dist);
                }
            }
            fclose(pf);
            printf("save to %s\n", save_file);
        }
    
   
  

   // for(int k = 0; k < files.size(); k++) {
   //     string cur_file = files[k];
        string cur_file = save_file;
        string rgb_img_file, depth_img_file, camera_pose_file;
        
        vector<cv::Point2d> img_pts;
        vector<cv::Point3d> wld_pts_gt;
        vector< vector<cv::Point3d> > wld_pts_pred_candidate;
        vector< vector<double > > candidate_feature_dists;
        bool is_read = Ms7ScenesUtil::load_prediction_result_with_distance(cur_file.c_str(), rgb_img_file, depth_img_file, camera_pose_file,
                                                                        img_pts, wld_pts_gt, wld_pts_pred_candidate, candidate_feature_dists);
        
        assert(is_read);
        rgb_img_files.push_back(rgb_img_file);
        depth_img_files.push_back(depth_img_file);
        camera_pose_files.push_back(camera_pose_file);
        
       
        cv::Mat depth_img;
        CvxIO::imread_depth_16bit_to_64f(depth_img_file.c_str(), depth_img);
        
        cv::Mat camera_to_world_pose = Ms7ScenesUtil::read_pose_7_scenes(camera_pose_file.c_str());
        
        cv::Mat mask;
        cv::Mat camera_coordinate_position;
        cv::Mat wld_coord = Ms7ScenesUtil::cameraDepthToWorldCoordinate(depth_img,
                                                            camera_to_world_pose,
                                                            calibration_matrix,
                                                            depth_factor,
                                                            min_depth,
                                                            max_depth,
                                                            camera_coordinate_position,
                                                            mask);
        
        // 2D location to 3D camera coordiante location*
        vector<vector<cv::Point3d> > valid_wld_pts_candidate;
        vector<cv::Point3d> valid_camera_pts;
        for(int i = 0; i<img_pts.size(); i++) {
            int x = img_pts[i].x;
            int y = img_pts[i].y;
            if(mask.at<unsigned char>(y, x) != 0) {
                cv::Point3d p = cv::Point3d(camera_coordinate_position.at<cv::Vec3d>(y, x));
                valid_camera_pts.push_back(p);
                valid_wld_pts_candidate.push_back(wld_pts_pred_candidate[i]);
            }
        }
        
        cv::Mat estimated_camera_pose = cv::Mat::eye(4, 4, CV_64F);
        if (valid_camera_pts.size() < 20) {
            angle_errors.push_back(180.0);
            translation_errors.push_back(10.0);
            estimated_poses.push_back(estimated_camera_pose);
            continue;
        }
        
        // estimate camera pose using Kabsch
        PreemptiveRANSAC3DParameter param;
        param.dis_threshold_ = inlierThreshold;
        bool isEstimated = CvxPoseEstimation::preemptiveRANSAC3DOneToMany(valid_camera_pts, valid_wld_pts_candidate, param, estimated_camera_pose);
        if (isEstimated) {
            double angle_dis = 0.0;
            double location_dis = 0.0;
            cv::Mat gt_pose = Ms7ScenesUtil::read_pose_7_scenes(camera_pose_file.c_str());
            CvxPoseEstimation::poseDistance(gt_pose, estimated_camera_pose, angle_dis, location_dis);
            angle_errors.push_back(angle_dis);
            translation_errors.push_back(location_dis);
            printf("angle distance, location distance are %lf %lf\n", angle_dis, location_dis);
        }
        else
        {
            angle_errors.push_back(180.0);
            translation_errors.push_back(10.0);
        }
        estimated_poses.push_back(estimated_camera_pose);
        
        if (k % 10 == 0) {
            // number of cameras inside threshold
            int num_small_error_cameras = 0;
            for (int i = 0; i<angle_errors.size(); i++) {
                if (angle_errors[i] < angleThreshold && translation_errors[i] < distanceThreshold) {
                    num_small_error_cameras++;
                }
            }
            printf("--------------------------camera number %lu, good pose percentage is %lf, threshold(%lf %lf)-------------------\n", angle_errors.size(),
                   1.0 * num_small_error_cameras/angle_errors.size(), angleThreshold, distanceThreshold);
        }
    }
    assert(angle_errors.size() == translation_errors.size());
   // assert(angle_errors.size() == files.size());
    
    // number of cameras inside threshold
    int num_small_error_cameras = 0;
    for (int i = 0; i<angle_errors.size(); i++) {
        if (angle_errors[i] < angleThreshold && translation_errors[i] < distanceThreshold) {
            num_small_error_cameras++;
        }
    }
    printf("good pose estimation percentage is %lf, threshold(%lf %lf)\n", 1.0 * num_small_error_cameras/angle_errors.size(), angleThreshold, distanceThreshold);
    
    std::sort(angle_errors.begin(), angle_errors.end());
    std::sort(translation_errors.begin(), translation_errors.end());
    printf("median angle error: %lf, translation error: %lf\n", angle_errors[angle_errors.size()/2], translation_errors[translation_errors.size()/2]);
    
   // assert(estimated_poses.size() == files.size());
  //  assert(estimated_poses.size() == rgb_img_files.size());
  //  assert(estimated_poses.size() == depth_img_files.size());
  //  assert(estimated_poses.size() == camera_pose_files.size());
    for (int k = 0; k<estimated_poses.size(); k++) {
        char save_file[1024] = {NULL};
        sprintf(save_file, "%s_%06d.txt", prefix, k);
        FILE *pf = fopen(save_file, "w");
        assert(pf);
        fprintf(pf, "%s\n", rgb_img_files[k].c_str());
        fprintf(pf, "%s\n", depth_img_files[k].c_str());
        fprintf(pf, "%s\n", camera_pose_files[k].c_str());
        Mat pose = estimated_poses[k];
        for (int r = 0; r<4; r++) {
            for (int c = 0; c<4; c++) {
                fprintf(pf, "%lf\t", pose.at<double>(r, c));
            }
            fprintf(pf, "\n");
        }
        fclose(pf);
    }
    printf("save to %s\n", prefix);
    
    
    return 0;
}

#endif
